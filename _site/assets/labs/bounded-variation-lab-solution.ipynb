{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Summary\n",
    "\n",
    "Today, we're going to be implementing least squares regression subject to a bound on *total variation*. That is, we're going to find a curve $\\hat \\mu$ on $[0,1]$ that solves this optimization problem.\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\hat \\mu &= \\operatorname*{argmin}_{\\substack{m \\\\ \\rho_{TV}(m) \\le B}} \\frac{1}{n}\\sum_{i=1}^n \\{ Y_i - m(X_i) \\}^2 \\qquad \\text{ where } \\\\  & \\rho_{TV}(m) = \\max_{\\substack{\\text{increasing sequences} \\\\ 0=x_1 \\le x_2 \\le \\ldots \\le x_k=1}}\n",
    "                  \\sum_{j=1}^{k-1} \\left\\lvert m(x_{j+1})-m(x_j) \\right\\rvert.\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "This is going to be a lot like implementing monotone regression. In fact, I changed only three lines of my implementation of monotone regression. And two of those are boilerplate. I'll give you those, so ultimately the change you'll be writing is a one-liner.\n",
    "But there is another issue that we didn't have to deal with before. We have to choose a sensible value of the variation budget $B$. We'll take a look at how this impacts the curve we get and consider *cross-validation* as a strategy for choosing it automatically.\n",
    "\n",
    "We'll use a few libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "suppressPackageStartupMessages({\n",
    "    library(tidyverse)\n",
    "    library(CVXR)\n",
    "})\n",
    "\n",
    "# OSQP claims some feasible problems aren't, so we'll tell CVXR not to use it\n",
    "CVXR::add_to_solver_blacklist('OSQP')  \n",
    "\n",
    "# And we'll style our plots  \n",
    "theme_update(plot.background = element_rect(fill = \"transparent\", colour = NA),\n",
    "\t\t    panel.background = element_rect(fill = \"transparent\", colour = NA),\n",
    "                    legend.background = element_rect(fill=\"transparent\", colour = NA),\n",
    "                    legend.box.background = element_rect(fill=\"transparent\", colour = NA),\n",
    "                    legend.key = element_rect(fill=\"transparent\", colour = NA),\n",
    "\t\t\tpanel.grid.major=element_line(color=rgb(1,0,0,.1,  maxColorValue=1)),\n",
    "\t        panel.grid.minor=element_line(color=rgb(0,0,1,.1,  maxColorValue=1)),\n",
    "\t\t    axis.ticks.x = element_blank(),\n",
    "\t\t    axis.ticks.y = element_blank(),\n",
    "\t\t    axis.text.x  = element_text(colour = \"#aaaaaa\"),\n",
    "\t\t    axis.text.y  = element_text(colour = \"#aaaaaa\"),\n",
    "\t\t    axis.title.x  = element_text(colour = \"#aaaaaa\"),\n",
    "\t\t    axis.title.y  = element_text(colour = \"#aaaaaa\", angle=90))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the function `invert.unique` from the monotone regression lab. We'll be using this all the time. It takes a vector $X$ and returns a list of two things.\n",
    "\n",
    "1. A vector `elements` cointaining the positions of the unique elements of $X$, so that `X[elements]` is vector of unique elements of $X$ sorted in increasing order. \n",
    "    - This vector has length $p$ where $p$ is the number of unique elements in $X$.\n",
    "2. A vector `inverse` that tells you, for each $i$, the position of $X[i]$ in $X[elements]$. \n",
    "    - This vector has length $n$ where $n$ is the length of $X$.\n",
    "    - `X[elements][inverse]` is the same as `X`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "invert.unique = function(x) { \n",
    "  o = order(x)\n",
    "  dup = duplicated(x[o])\n",
    "  inverse = rep(NA, length(x))\n",
    "  inverse[o] = cumsum(!dup)\n",
    "  list(elements=o[!dup], inverse=inverse)\n",
    "}\n",
    "\n",
    "a = c(1,2,3,3,4,5,5,5,6)\n",
    "unique.a=invert.unique(a)\n",
    "stopifnot(a[unique.a$elements][unique.a$inverse] == a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation\n",
    "\n",
    "Much like we did with monotone regression, it'll help to start by solving for a function $\\hat\\mu_{\\mathcal{X}}$ \n",
    "that \n",
    "\n",
    "RESTRICTION AND EXPANSION\n",
    "\n",
    "\n",
    "with a constraint defined on the sample. In particular, we'll work with a seminorm $\\hat\\rho_{TV}$ which, instead of being defined as a maximum over all increasing sequences, uses a single increasing sequence: the observations $X_1 \\le X_2 \\le \\ldots \\le X_n$, which we will assume we have sorted into increasing order throughout. That is, we'll solve this finite-dimensional optimization problem.\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\hat \\mu &= \\operatorname*{argmin}_{\\substack{m \\\\ \\hat\\rho_{TV}(m) \\le B}} \n",
    "            \\frac{1}{n}\\sum_{i=1}^n \\{ Y_i - m(X_i) \\}^2 \\qquad \\text{ where } \\\\ \n",
    "&\\hat\\rho_{TV}(m) = \\sum_{i=1}^{n-1} \\left\\lvert m(X_{i+1})-m(X_i) \\right\\rvert.\n",
    "\\end{aligned}\n",
    "$$ \n",
    "\n",
    "As in the analogous problem we discussed when doing monotone regression, both our squared error and our constraint depend only on the values $m(X_1) \\ldots m(X_n)$ of $m$. And if we have the values $\\hat\\mu^{\\text{sample}}(X_1) \\ldots \\hat\\mu^{\\text{sample}}(X_n)$ of a solution to this problem, we can easily find a solution to our original problem. In fact, you already have code to do it. Let me explain.\n",
    "\n",
    "## From Bounded Variation on the Sample to Bounded Variation\n",
    "\n",
    "The short answer is that we can take $\\hat \\mu(x)$ to be any curve that agrees with $\\hat \\mu^{\\text{sample}}$ at $X_1 \\ldots X_n$, is *monotone* between the observations, and is *constant* outside the range of the data. Typically, we use piecewise-constant interpolation, defining $\\hat \\mu(x)$ to be $\\hat \\mu^{\\text{sample}}(X_i)$ where $X_i$ is the closest observation to the left of $x$ if $x$ is inside the range of the data and the leftmost observation otherwise: $X_i=\\max\\ \\{X_i : X_i \\le x\\} \\cup \\{X_1\\}$. That's what the function `predict.piecewise.constant` we've been using with monotone regression does.\n",
    "\n",
    "Here's why this gives us a solution to our original problem. The explanation is based on three observations.\n",
    "\n",
    "1.  Any curve we're considering in our original optimization also gets considered in our finite-dimensional analog. That is, $\\hat\\rho_{TV}(m) \\le \\rho_{TV}(m)$ for any curve $m$ and therefore $$ \\left\\{ m : \\rho_{TV}(m) \\le B\\right\\} \\subseteq \\left\\{ m : \\hat\\rho_{TV}(m) \\le B \\right\\} $$ We know this because $\\hat\\rho_{TV}(m)$ is the sum $\\sum_{i=1}^{n-1} \\left\\lvert m(X_{i+1})-m(X_i) \\right\\rvert$ for a particular increasing sequence $X_1 \\ldots X_n$ and $\\rho_{TV}(m)$ the maximum of *the same sum* over all increasing sequences $X_1 \\ldots X_n$.\n",
    "\n",
    "2.  This implies that any curve $\\hat\\mu$ that solves our original optimization would be considered in our finite-dimensional analog, so the prediction error that we're minimizing in both problems, $\\text{MSPE}(m)=\\frac{1}{n}\\sum_{i=1}^n \\{ Y_i - m(X_i) \\}^2$, is *at least as small* at a solution $\\hat\\mu_{\\text{sample}}$ to the finite-dimensional version as it is in the original problem. Consequently, if a solution $\\hat\\mu_{\\text{sample}}$ to our finite-dimensional problem satisfies the stronger constraint $\\rho_{TV}(m) \\le B$ needed to be considered in the original problem, it's also a solution to the original problem: it has the smallest $\\text{MSPE}$ among curves in the set $\\left\\{ m : \\hat\\rho_{TV}(m) \\le B \\right\\}$, so it must have the smallest $\\text{MSPE}$ among any subset of those curves, including $\\left\\{ m : \\rho_{TV}(m) \\le B \\right\\}$.\n",
    "\n",
    "3.  For any curve $m^{\\text{sample}}$, we can find a curve $m$ that *agrees on the sample*, i.e. with $m(X_i) = m^{\\text{sample}}(X_i)$, that has total variation *equal to* its sample total variation. The piecewise-constant curve we've been drawing is one of them: all of its variation is at the sample points. Furthermore, because it agrees with $m^{\\text{sample}}$ on the sample, it has the same $\\text{MSPE}$. That means the piecewise-constant curve we've proposed through the points $\\hat\\mu^{\\text{sample}}(X_i)$ is a solution to the finite-dimensional problem and satisfies the stronger constraint imposed in the original problem. Thus, it's a solution to the original problem.\n",
    "\n",
    "To reinforce your understanding of this argument, do this exercise. We'll work with a sample of three points $(X_i,Y_i)$. $$ \\left\\{\\left(0, \\frac{1}{2}\\right), \\left(\\frac{1}{2},0\\right), \\left(1,\\frac{1}{4}\\right)\\right\\} $$You can think of what we'll be doing as stepping through our approach to bounded variation regression in a world in which there are only six curves: $m_1(x)=x^2$, $m_2(x) = 3(x-1/2)^2$, $m_3(x) = 2(x-3/4)^2$, and corresponding piecewise-constant curves $\\tilde m_1$, $\\tilde m_2$, and $\\tilde m_3$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Draw each of these six curves. I suggest you draw three plots in total: one of $m_1$ and $\\tilde m_1$ together, another of $m_2$ and $\\tilde m_2$, and another of $m_3$ and $\\tilde m_3$. For each, calculate the sample total variation $\\hat\\rho_{TV}(m)$ and the total variation $\\rho_{TV}(m)$. \n",
    "Of these curves, which minimize mean squared prediction error among the curves with $\\hat\\rho_{TV}(m) \\le 1$? And which minimize it among the curves with $\\rho_{TV}(m) \\le 1$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Solving the Finite-dimensional Problem\n",
    "\n",
    "All this leaves is finding the values $\\hat\\mu_{\\text{sample}}(X_i)$ of a solution to the finite-dimensional optimization problem. As in the Monotone Regression Lab, we can almost get away with substituting the elements $\\vec m_i$ of a vector $\\vec m \\in \\mathbb{R}^n$ for the function values $m(X_1) \\ldots m(X_n)$. The one wrinkle is that we need to make sure these elements correspond to the values of a function, i.e., that the vector satisfies $\\vec m_i = \\vec m_j$ if $X_i=X_j$. That is,\n",
    "\n",
    "\n",
    "$$\n",
    "\\hat \\mu(X_i) = \\vec \\mu_i \\ \\text{ where } \\ \\vec \\mu = \n",
    "\\operatorname*{argmin}_{\\substack{\\vec m \\in \\mathbb{R}^n \\\\\n",
    "                   \\sum_{i=1}^{n-1} \\left\\lvert \\vec m_{i+1} - \\vec m_i\\right\\rvert \\le B \n",
    "                   \\\\ \\vec m_{i+1} = \\vec m_i \\ \\text{ for all $i$ with $X_{i+1}=X_i$}}}               \n",
    "                   \\frac{1}{n}\\sum_{i=1}^n (Y_i - \\vec m_i)^2. \n",
    "$$\n",
    "\n",
    "\n",
    "We covered this in the Optimized Implementation Section of the Monotone Regression Lab."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a very similar optimization to the one we used for monotone regression. We're still optimizing over a vector $\\vec{m}$ of $n$ values with the interpretation $\\vec{m}_i=m(X_i)$. We're still minimizing mean squared prediction error. All we've got to do is change our constraint. \n",
    "To save you some trouble, I've copied my monotone regression code into the block below. And I've handled some boilerplate changes for you, too.\n",
    "\n",
    "1.  I've changed the name and arguments of the function (line 1).\n",
    "2.  I've changed the 'class' attribute in the output so *R* knows it's a bounded variation regression rather than a monotone one (line 36).\n",
    "3.  I've defined 'predict.bvreg' to do piecewise-constant interpolation like we did in the monotone regression lab (line 72).\n",
    "\n",
    "That means that all you have to do is change the constraint. The one that's on line 22 in the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "solution"
    ],
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "bvreg = function(X, Y, B=1) {\n",
    "  # Step 0.\n",
    "  # We check that the inputs satisfy our assumptions.\n",
    "  stopifnot(length(X) == length(Y))\n",
    "  input = list(X=X, Y=Y)\n",
    "  n = length(X)\n",
    "  # and find the unique elements of X and the inverse mapping\n",
    "  unique.X = invert.unique(X)\n",
    "\n",
    "  # Step 1.\n",
    "  # We tell CVXR we're thinking about a vector of unknowns m in R^p.\n",
    "  m = Variable(length(unique.X$elements))\n",
    "  # and permute and duplicate these into a vector mX with n elements in correspondence with (X_1,Y_1)...(X_n,Y_n)\n",
    "  mX = m[unique.X$inverse]\n",
    "\n",
    "  # Step 2.\n",
    "  # We tell CVXR that we're interested in mean squared error.\n",
    "  mse = sum((Y - mX)^2 / n)\n",
    "\n",
    "  # Step 3.\n",
    "  # We specify our constraints.\n",
    "  constraints = list( sum(abs(diff(m))) <= B )\n",
    "\n",
    "  # Step 4.\n",
    "  # We ask CVXR to minimize mean squared error subject to our constraints.\n",
    "  # And we ask for vector mu.hat that does it.\n",
    "  solved = solve(Problem(Minimize(mse), constraints))\n",
    "  mu.hat = solved$getValue(m)\n",
    "\n",
    "  # Step 5: a little boilerplate to make it idiomatic R.\n",
    "  # 1. we record the unique levels of X and mu.hat, in correspondence and sorted in increasing order of X, in a list. We also record the input data. \n",
    "  # 2. we assign that list a class, so R knows predict should delegate to predict.monotonereg\n",
    "  # 3. we return the list\n",
    "  model = list(X = X[unique.X$elements], mu.hat = mu.hat, input = input)\n",
    "  attr(model, \"class\") = \"bvreg\"\n",
    "  model\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# make predictions based on piecewise-constant interpolation\n",
    "# we use the curve that jumps at each observation and is otherwise constant\n",
    "# that is, if X[1] < X[2] < ..., \n",
    "#   mu.hat(x) for x between X[k] and X[k+1] is mu.hat(X[k])   [case 1]\n",
    "#             for x > X[k]  is mu.hat(X[k])                   [case 2]\n",
    "#             for x < X[1]  is mu.hat(X[1])                   [case 3]\n",
    "predict.bvreg = function(model, newdata=data.frame(X=model$input$X)) {\n",
    "  y = model$mu.hat; X=model$X; x=newdata$X\n",
    "  # for each new data point x in newdata$X, \n",
    "  # find the closest observed X[k] left of x\n",
    "  # i.e., the largest k for which X[k] <= x \n",
    "  # this covers cases 1 and 2\n",
    "  # bin will be a vector of these numbers k, with one for each x in newdata$X\n",
    "  bin = findInterval(x, X) \n",
    "  # if there is no X[k] < x, findInterval tells us k=0\n",
    "  # to cover case 3, we want X[k] for k=1 when this happens.\n",
    "  bin[bin==0] = 1\n",
    "  # report the values of mu.hat(X[k]), one for each x\n",
    "  y[bin]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Write some stuff here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "prediction.function = function(model) {\n",
    "  function(x) { predict(model, data.frame(X=x)) }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Once you've got code, try fitting some data to see that it works. You can just run this block, but it might be instructive to try changing the variation budget $B$ and look at how the fit changes. Or try changing the function $\\mu$ from the step to something else and see how the fit changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "mu = function(x) { 1*(x >= .5) }\n",
    "sigma = .5\n",
    "n = 400\n",
    "X = runif(n)\n",
    "Y = mu(X) + sigma*rnorm(n)\n",
    "\n",
    "x = seq(0,1,by=.001) \n",
    "mu.hat = prediction.function(bvreg(X,Y, B=1))\n",
    "ggplot() + geom_point(aes(x=X,y=Y), alpha=.2) +\n",
    "           geom_line(aes(x=x, y=mu(x)), alpha=.4) +\n",
    "           geom_line(aes(x=x,y=mu.hat(x)), color='blue')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Behavior\n",
    "\n",
    "Now that we've got some bounded variation regression code, let's see how it works and how that depends on the variation budget $B$. We'll try fitting data sampled around four simple curves. Data that looks like this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "n=200\n",
    "sigma = .5\n",
    "mus = list(step     = function(x) { 1*(x >= .5) },\n",
    "\t         line     = function(x) { x },\n",
    "\t         stepline = function(x) { x*(x >= .5) }, \n",
    "\t         sin      = function(x) { sin(pi*x) })\n",
    "           \n",
    "x = seq(0,1,by=.01)\n",
    "for(mu.name in names(mus)) { \n",
    "    mu = mus[[mu.name]]\n",
    "    X     = runif(n)\n",
    "    epsilon     = sigma*rnorm(length(X))\n",
    "    Y = mu(X) + epsilon\n",
    "    print(ggplot() + \n",
    "      geom_line(aes(x=x, y=mu(x)), alpha=.5) + \n",
    "        geom_point(aes(x=X, y=Y), alpha=.2))  \n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "For each curve $\\mu$, we'll do the following.\n",
    "\n",
    "1.  Sample $n=200$ some observations $(X_i,Y_i)$ with\n",
    "\n",
    "    -   $X_i$ uniformly distributed on $[0,1]$\n",
    "    -   $Y_i = \\mu(X_i) + \\varepsilon_i$ where $\\varepsilon_i \\sim N(0,\\sigma^2)$ for $\\sigma=.5$.\n",
    "\n",
    "    And sample independent copies $(\\tilde X_i,\\tilde Y_i)$ from the same distribution.\n",
    "\n",
    "2.  Use our code to find estimates $\\hat\\mu$ of the curve using variation budgets $B \\in \\{1/10,\\ 1/4,\\ 1/2,\\ 1,\\ 2,\\ 4,\\ 10\\}$.\n",
    "\n",
    "3.  For each of these estimates, calculate\n",
    "\n",
    "    -   Training Error, $\\frac1n\\sum_{i=1}^n \\{ \\hat\\mu(X_i) - Y_i \\}^2$\n",
    "    -   Test Error, $\\frac1n\\sum_{i=1}^n \\{ \\hat\\mu(\\tilde X_i) - \\tilde Y_i \\}^2$\n",
    "    -   Population MSE, $\\int_0^1 \\{ \\hat\\mu(x) - \\mu(x)\\}^2 dx + \\sigma^2$.  \n",
    "\n",
    "    Adding $\\sigma^2$ to the last error makes it comparable to the others, which are sensitive to the noise level.\n",
    "\n",
    "We'll do it all 10 times and average the results to get a decent approximation to the expectation of each of these error measures. Let's run the blocks below to tabulate there errors. It will take a few minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "training.error = function(mu.hat, d) { \n",
    "  mean((mu.hat(d$X)-d$Y)^2)\n",
    "}\n",
    "test.error     = function(mu.hat, d) { \n",
    "  mean((mu.hat(d$Xtest)-d$Ytest)^2)\n",
    "}\n",
    "population.mse = function(mu.hat, d) { \n",
    "  x=seq(0,1,by=.001)\n",
    "  mean((mu.hat(x) - d$mu(x))^2) + sigma^2\n",
    "}   \n",
    "errors = list(training=training.error, \n",
    "              test=test.error, \n",
    "              population=population.mse)\n",
    "\n",
    "Bs = c(.1,.25,.5,1,2,4,10)\n",
    "models = Bs |> \n",
    "  map(\\(B) \\(X,Y) bvreg(X,Y,B)) |> \n",
    "  set_names(sprintf('tv=%1.2f', Bs))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "on_sample = function(f, mu, sigma, n) {\n",
    "    X     = runif(n)\n",
    "    Xtest = runif(n)\n",
    "    epsilon     = sigma*rnorm(length(X))\n",
    "    epsilontest = sigma*rnorm(length(X))\n",
    "    Y = mu(X) + epsilon\n",
    "    Ytest = mu(Xtest) + epsilontest\n",
    "    dataset = list(mu=mu,X=X,Y=Y,Xtest=Xtest,Ytest=Ytest)\n",
    "    f(dataset)\n",
    "}\n",
    "\n",
    "summarize_fit = function(models) {\n",
    "  function(d) {\n",
    "    map(models, \\(fit.model) { \n",
    "      model = fit.model(d$X,d$Y)\n",
    "      mu.hat = prediction.function(model)\n",
    "      errors |> map(\\(e) data.frame(error=e(mu.hat, d))) |>\n",
    "                list_rbind(names_to='error.measure') |>\n",
    "                mutate(B=model$B)\n",
    "    }) |> list_rbind(names_to='model')\n",
    "  }\n",
    "} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "tab = 1:10 |> map(\\(rep) { \n",
    "  mus |> map(\\(mu) \n",
    "  summarize_fit(models) |> \n",
    "  on_sample(mu, sigma, n)\n",
    "  ) |> list_rbind(names_to='mu')\n",
    "}) |> list_rbind(names_to='rep') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Here's what we get.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "ggplot(tab, \n",
    "       aes(x=B, y=error, linetype=error.measure, shape=error.measure)) + \n",
    "  geom_point(alpha=.2, position=position_jitter(w=.1)) + \n",
    "  stat_summary(geom='line',  fun=mean) +\n",
    "  stat_summary(geom='point', fun=mean) +\n",
    "  facet_grid(cols=vars(mu))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Why Test Error and Population MSE agree so well\n",
    "\n",
    "What we see in this plot is that Test Error and $\\text{Population MSE} + \\sigma^2$ are very close. That means we can effective choose our variation budget $B$ to minimize Population MSE. \n",
    "That's something we can't compute in practice because we'd need knowledge of $\\mu$ and the distribution of $X$ to do it, but because test error tracks it so well, we get the same effect by choosing $B$ to minimize test error.\n",
    "Test Error is, in fact, an *unbiased* estimate of $\\text{Population MSE} + \\sigma^2$. This is a pretty straightforward calculation. Letting $\\tilde E$ denote expectation conditional on the training observations ...\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\tilde{E} \\{ \\tilde Y_i - \\hat\\mu(\\tilde X_i)\\}^2 \n",
    "&= \\tilde{E} \\{\\tilde \\varepsilon_i + \\mu(\\tilde X_i) - \\hat \\mu(\\tilde X_i)\\}^2 \\quad \\text{ for } \\quad \\tilde \\varepsilon_i = \\tilde Y_i - \\mu(\\tilde X_i) \\\\ \n",
    "&= \\tilde{E} \\tilde\\varepsilon_i^2 + \\tilde{E} \\{\\mu(\\tilde X_i) - \\hat\\mu(\\tilde X_i)\\}^2 +\n",
    "  2\\tilde{E} \\tilde \\varepsilon_i \\{\\mu(\\tilde X_i) - \\hat\\mu(\\tilde X_i)\\} \\\\\n",
    "&= \\sigma^2 + \\text{PMSE} + 0\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Unbiasedness is, of course, not the whole story. Some unbiased estimates are usually nowhere near the quantity they're estimating. But this isn't just an unbiased estimate. It's an *average* of $n$ independent terms, each of which is an unbiased estimate of the same quantity. \n",
    "Roughly how far apart, as a function of sample size $n$, would you expect them to be? Does what you say require the noise $\\varepsilon_i$ to be independent of $X_i$ or is it true in greater generality?.\n",
    "\n",
    "*Hint.* What is the expectation of adjusted test error conditional on the training observations? And what is the conditional variance?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overfitting\n",
    "\n",
    "Explain why training error tends to zero as $B$ increases. Why does test error not have this problem?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model selection\n",
    "\n",
    "Since the variation budget $B$ matters, it's important to choose it well. Ideally, we'd do it automatically. Give it a shot.\n",
    "Propose and implement an automated approach to choosing the variation budget $B$ in the block below.\n",
    "\n",
    "**Hint**. Do we have an error measure that is both sensible and computable? To keep things simple, I'll ask that you choose from a finite set of options $\\{B_1 \\ldots B_k\\}$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Let's see how well this works. We'll look at error varies as a function of sample size for bounded variation regression with a few fixed budgets, as well as with a budget chosen by this procedure.\n",
    "To do this, we'll make a table of errors at different sample sizes, then do some visualization. Since everything is random, we'll do all this 10 times, average the results, and take a look at how variable these results are. \n",
    "\n",
    "Run the block below to make the table. It may take a few minutes. Keep in mind that if you haven't finished some of the previous exercises, the results you'll get might look pretty odd.\n",
    "For example, if your version of the function `tvreg` above is really just monotone regression, varying the budget won't do anything. And if you haven't implemented the model selection procedure, you'll just get a comparison of the fixed budget-approaches. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "on_samples = function(f, mu, sigma, ns) {\n",
    "    X     = runif(max(ns))\n",
    "    Xtest = runif(max(ns))\n",
    "    epsilon     = sigma*rnorm(length(X))\n",
    "    epsilontest = sigma*rnorm(length(X))\n",
    "    Y = mu(X) + epsilon\n",
    "    Ytest = mu(Xtest) + epsilontest\n",
    "    ns |> map(\\(n) {\n",
    "      dataset = list(mu=mu,X=X[1:n],Y=Y[1:n],Xtest=Xtest[1:n],Ytest=Ytest[1:n])\n",
    "      f(dataset) |> mutate(n=n)\n",
    "    }) |> list_rbind()\n",
    "}\n",
    "bvmodel = function(B) { function(X,Y) { bvreg(X, Y, B=B) }}\n",
    "bvselected = function(Bs) {\n",
    "  function(X,Y) { \n",
    "    B = select.budget(X,Y,Bs)\n",
    "    bvreg(X,Y,B=B)\n",
    "  }\n",
    "}\n",
    "models  = list(bv0.5      = bvmodel(.5),\n",
    "               bv1        = bvmodel(1),\n",
    "               bv2        = bvmodel(2),\n",
    "               bv4        = bvmodel(4),\n",
    "               bvselected = bvselected(c(.5,1,2,4)))\n",
    "\n",
    "\n",
    "ns = c(25,50,100)\n",
    "grid = expand_grid(rep=1:10, mu=names(mus))\n",
    "tab = grid |> \n",
    "  pmap(\\(rep, mu) on_samples(summarize_fit(models), mus[[mu]], sigma, ns) |> mutate(rep=rep, mu=mu)) |>\n",
    "  list_rbind() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Now run this block to plot the error curves for each of our models. What we're seeing in bold color are the means of our error measures plus/minus one standard error. This gives us a sense of which method performs best of average. To illustrate how random performance is---how much it varies when we repeat the experiment---we'll also plot the error curves for each of our 10 trials faintly. This is called a *spaghetti plot*. They tend to be a bit of a mess, but they do give you an opportunity to get a gestalt impression of what's going on without committing to any particular summary statistic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "for(mu in names(mus)) {\n",
    "  plot.data = tab[tab$mu == mu, ]\n",
    "  print(ggplot(plot.data, aes(x=n, y=error, color=model)) + \n",
    "    geom_line(aes(group=interaction(model,rep), color=model), alpha=.3, linewidth=.5) +\n",
    "    stat_summary(geom='line',  fun=mean, position=position_dodge(width = 3)) +\n",
    "    stat_summary(geom='pointrange', fun.data=mean_se, position=position_dodge(width=3)) +\n",
    "    facet_grid(cols=vars(error.measure)) + ggtitle(mu))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "How does your model selection code perform relative to the other methods? Does it tend to come in first, second, etc in terms of its accuracy? Why? "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
